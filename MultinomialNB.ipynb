{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MultinomialNB.ipynb","version":"0.3.2","provenance":[{"file_id":"1FaS6iXsT4W7_akCTBldqk99bDi-VBMZe","timestamp":1555366608333},{"file_id":"1w0OhxCRXOiXIE709ppimuyjhgTBWwyGF","timestamp":1553800018979},{"file_id":"1zJVHvCJnuun9Zi4OGt9Pw5pWXVgNIGNk","timestamp":1553730163748}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"L3mZjARJG29x","colab_type":"text"},"source":["# **Get Data** \n"]},{"cell_type":"code","metadata":{"id":"j4QgUPH0tJLK","colab_type":"code","outputId":"2702a03b-66c5-411d-e56d-0a816712df6c","executionInfo":{"status":"ok","timestamp":1557432920515,"user_tz":420,"elapsed":5105,"user":{"displayName":"Andrea Cruz Castillo","photoUrl":"","userId":"02285616348107227719"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["#from google.colab import drive\n","#drive.mount('/content/gdrive')\n","!git clone https://github.com/AndreaJJCC/CategorySuggestion.git"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'CategorySuggestion'...\n","remote: Enumerating objects: 18, done.\u001b[K\n","remote: Counting objects: 100% (18/18), done.\u001b[K\n","remote: Compressing objects: 100% (15/15), done.\u001b[K\n","remote: Total 18 (delta 4), reused 14 (delta 2), pack-reused 0\u001b[K\n","Unpacking objects: 100% (18/18), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6KpL8ZlM8hDC","colab_type":"text"},"source":["# **Import Necessary Libraries**"]},{"cell_type":"code","metadata":{"id":"BMikM-DS8t9p","colab_type":"code","colab":{}},"source":["# Imports\n","import json #lines\n","import pandas as pd\n","import re \n","import os\n","from nltk.stem import PorterStemmer\n","import numpy as np\n","from sklearn.naive_bayes import MultinomialNB\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F57WoLGjd_lo","colab_type":"code","outputId":"999a15c3-e0e8-4f35-962b-fc7f6f7e3b78","executionInfo":{"status":"ok","timestamp":1557432925131,"user_tz":420,"elapsed":9685,"user":{"displayName":"Andrea Cruz Castillo","photoUrl":"","userId":"02285616348107227719"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["os.chdir('/content/CategorySuggestion/')\n","!unzip -o /content/CategorySuggestion/features.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Archive:  /content/CategorySuggestion/features.zip\n","  inflating: features.json           \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HUAwUuuS6DlJ","colab_type":"code","colab":{}},"source":["# Define file paths\n","main_dir = '/content/CategorySuggestion/'\n","features_dir = main_dir + 'features.json'\n","sets_dir = main_dir + 'sets.json'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GYgSn8fpJJad","colab_type":"text"},"source":["# **Helper Functions**"]},{"cell_type":"code","metadata":{"id":"-9RcdPdhfIVJ","colab_type":"code","colab":{}},"source":["# Define function to duplicate data from main dataframe\n","# Input: dataframe\n","# Output: dataframe with duplicated records (one copy of record per category in categories column)\n","def duplicate_data(dataframe):\n","  \n","  i = 0\n","  cat_list = []   # list of single categories for duplicated records\n","  duplicate = []  # list of number of times a record must be duplicated\n","  # For the category list of each record\n","  for lst in dataframe.categories:\n","    if lst == dataframe.categories[i]:\n","      # save the number of times a record will be duplicate -> len(lst) times\n","      # (appends an int to duplicate list, which is used later)\n","      duplicate.append(len(lst))\n","      # Also form a list of individual category labels for duplicated records\n","      # i.e. Record 1) [restautarant, bars]\n","      #      Record 2) [food, tea] \n","      # --> [[restaurant],[bars], [food], [tea]]\n","      for category in lst:\n","        cat_list.append(category)\n","      i = i + 1\n","      \n","  # duplicate each record based on the value of duplicate list    \n","  dataframe = dataframe.loc[np.repeat(dataframe.index.values, duplicate)].reset_index(drop = True)\n","  # Create column of individual labels for each record, including duplicated records\n","  dataframe['label'] = cat_list\n","  print(\"The number of single categories is \", len(cat_list))\n","  return  dataframe"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eeJ_amTNJHB9","colab_type":"code","colab":{}},"source":["# Creates a list of lists of the top N classes\n","# Input: model, from which we get the classes/labels\n","#        probabilities list, list of lists\n","#        N, the number of classes to return\n","# Output: returns a series of the top N classes of a given list\n","def getNclasses( model, probabilities, N):\n","\n","  topNclasses = [] # list that will contain top N classes for a given record\n","  # for each probabaility vector (for each record)\n","  for value in probabilities:\n","    # get tuple (probability, class/label)\n","    # sort probabilities in descending order\n","    # get top N tuples i.e. the tuples with higher probabilities\n","    tmp = sorted(zip(value, model.classes_), reverse=True)[:N]\n","\n","    topN = []\n","    # for each tuple (probabilities, class/label) only append the class/label\n","    # to the topN list for each record\n","    # i.e. for a given record: [(0.25, food), (0.2, tea), (0.1, bakery)]\n","    # it returns [food, tea, bakery]\n","    for e in tmp:\n","      topN.append(e[1])\n","    # then append this to the topNclasses list, which if list of lists\n","    # i.e. list of top N categories list\n","    # i.e topNClasses = [ [(record1) food, tea, bakery], [(record2) restaurant, bar] ] \n","    topNclasses.append(topN)\n","    \n","  return pd.Series(topNclasses)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B_2RTv73JYyb","colab_type":"code","colab":{}},"source":["# Compares two lists to check if the element in one list\n","# is contained in another list.\n","# Input: two list to be compared namely predicted and actual\n","#        measure, used to write to a text file. Measure specifies substring to be \n","#        used for the file name\n","# Output: in_list -> list of values, 0 => values in list1 are not in list2\n","#                         # => # of values of list1 that exist in list2\n","#         length-> number of actual labels for a given business\n","def compareLists( predicted, actual):\n"," \n","  tp_list, fp_list, length = [], [], [] # saves values for each record (tp/fp/len(actual))\n","  \n","  j = 0 # Index of predicted labels\n","  \n","  # For each actual_label, iterate and check if any of the predicted labels\n","  # are in the actual_label list\n","  for actual_label in actual:\n","    tp = 0 # True positives - Keep track of how many pred_label are actual_label\n","    fp = 0 # False negavtives - Keep track of how many pred_label are not actual_label\n","\n","    # iterate over predicted list. If any of the predicted labels appear\n","    # in actual_label cnt += 1, else cnt = 0\n","    for pred_label in predicted.iloc[j]:\n","      if str(pred_label) in actual_label:\n","        tp = tp + 1\n","      else:\n","        fp = fp +1\n","    # append the results for a given record to in_list\n","    tp_list.append(tp)\n","    fp_list.append(fp)\n","    length.append(len(actual_label))\n","    j = j + 1\n","\n","  return tp_list, fp_list, length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FrKvfBEOJiRt","colab_type":"code","colab":{}},"source":["# Compare the predicted classes from Naive Bayes\n","# to the sets returned by apriori algorithm\n","# Return the best(longest) matched sub/set\n","def compare_to_set(predicted, sets_list):\n","  myList = []\n","  prev = int()\n","  for pred in predicted: # prediction from Naive Bayes\n","      pred_vals = set(pred) # cast list to set\n","      longest_set = set()\n","      for item in reversed(sets_list): # itemsets returned by apriori\n","        if pred_vals >= item:  # if itemset is a subset of prediction by Naive Bayes\n","          temp_set = item & pred_vals # Intersection of both sets, returns elements in item and pred_vals\n","          longest_set.update(temp_set) # Update subset to get longest possible subset\n","          \"\"\"\"# If size of prev_subset > current subset break because\n","          # current subset is a subset of the previous subset\n","          # i.e. {'breakfast', 'cafes'} is a subset of {'breakfast', 'cafes', 'brunch'}\n","          if prev > len(item):\n","            myList.append(list(longest_set)) # append longest set to list that will be returned\n","            break\n","          prev = len(item)\n","          \"\"\"\n","      myList.append(list(longest_set))\n","  return myList"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aYTYetpN8vY0","colab_type":"text"},"source":["#**Load and Visualize Data**"]},{"cell_type":"code","metadata":{"id":"2XbEDRWx63il","colab_type":"code","colab":{}},"source":["# Define function to load files\n","# Input: file directory\n","# Output: dictionary of json objects\n","def load_data( directory):\n","  with open(directory) as f:\n","    data = []\n","    for line in f:\n","      data.append(json.loads(line))\n","  return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v8_1wd712OjB","colab_type":"code","outputId":"d0189318-ed8a-4b89-a743-d908d9012931","executionInfo":{"status":"ok","timestamp":1557432950235,"user_tz":420,"elapsed":34751,"user":{"displayName":"Andrea Cruz Castillo","photoUrl":"","userId":"02285616348107227719"}},"colab":{"base_uri":"https://localhost:8080/","height":279}},"source":["data_df = pd.DataFrame.from_dict(load_data(features_dir))\n","data_df = data_df.drop(columns =['tfidf_features'])\n","data_df.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>categories</th>\n","      <th>count_features</th>\n","      <th>name</th>\n","      <th>review_count</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>YIez_A3WOt9J2SXN7OMa2Q</td>\n","      <td>[caribbean, food, bakeries, restaurants]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>allwyns bakery</td>\n","      <td>105</td>\n","      <td>allwyns bakery love jerk chicken sandwich jerk...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>YkAIlxYZ1guSqbbowU9X4g</td>\n","      <td>[restaurants, chinese, dim, sum, breakfast, br...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>luckee</td>\n","      <td>171</td>\n","      <td>luckee came lovely dinner husband weeks ago gr...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2ktKjN5z8EcqmUv6EDiDgA</td>\n","      <td>[fashion, department, stores, automotive, shop...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>costco</td>\n","      <td>121</td>\n","      <td>costco got worth tires today told would long w...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ADmJgVJ82zdLzffdaH1gVw</td>\n","      <td>[food, specialty, food, organic, stores, healt...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>planet organic market</td>\n","      <td>14</td>\n","      <td>planet organic market given store many chances...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>V90fC_aF-_DNYzQvUtbLww</td>\n","      <td>[hotels, travel, asian, fusion, day, spas, cas...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>jayde fuzion</td>\n","      <td>246</td>\n","      <td>jayde fuzion locals decided try jayde since lo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              business_id                                         categories  \\\n","0  YIez_A3WOt9J2SXN7OMa2Q           [caribbean, food, bakeries, restaurants]   \n","1  YkAIlxYZ1guSqbbowU9X4g  [restaurants, chinese, dim, sum, breakfast, br...   \n","2  2ktKjN5z8EcqmUv6EDiDgA  [fashion, department, stores, automotive, shop...   \n","3  ADmJgVJ82zdLzffdaH1gVw  [food, specialty, food, organic, stores, healt...   \n","4  V90fC_aF-_DNYzQvUtbLww  [hotels, travel, asian, fusion, day, spas, cas...   \n","\n","                                      count_features                   name  \\\n","0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         allwyns bakery   \n","1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...                 luckee   \n","2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...                 costco   \n","3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  planet organic market   \n","4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...           jayde fuzion   \n","\n","   review_count                                               text  \n","0           105  allwyns bakery love jerk chicken sandwich jerk...  \n","1           171  luckee came lovely dinner husband weeks ago gr...  \n","2           121  costco got worth tires today told would long w...  \n","3            14  planet organic market given store many chances...  \n","4           246  jayde fuzion locals decided try jayde since lo...  "]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"oYLTDiUzMisz","colab_type":"code","outputId":"f2afbfc0-d425-41fb-ec21-3002dc59faaf","executionInfo":{"status":"ok","timestamp":1557432950237,"user_tz":420,"elapsed":34731,"user":{"displayName":"Andrea Cruz Castillo","photoUrl":"","userId":"02285616348107227719"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["with pd.option_context('display.max_rows', 4, 'display.max_columns', 4, 'max_colwidth', 100):\n","    display(data_df.head(3))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>categories</th>\n","      <th>...</th>\n","      <th>review_count</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>YIez_A3WOt9J2SXN7OMa2Q</td>\n","      <td>[caribbean, food, bakeries, restaurants]</td>\n","      <td>...</td>\n","      <td>105</td>\n","      <td>allwyns bakery love jerk chicken sandwich jerk chicken dinner roti always fresh would stay away ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>YkAIlxYZ1guSqbbowU9X4g</td>\n","      <td>[restaurants, chinese, dim, sum, breakfast, brunch]</td>\n","      <td>...</td>\n","      <td>171</td>\n","      <td>luckee came lovely dinner husband weeks ago great dining experience enjoyed dim sum ordered obvi...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2ktKjN5z8EcqmUv6EDiDgA</td>\n","      <td>[fashion, department, stores, automotive, shopping, wholesale, stores, tires]</td>\n","      <td>...</td>\n","      <td>121</td>\n","      <td>costco got worth tires today told would long wait theyd call done waited noon till pm tires done...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows Ã— 6 columns</p>\n","</div>"],"text/plain":["              business_id  \\\n","0  YIez_A3WOt9J2SXN7OMa2Q   \n","1  YkAIlxYZ1guSqbbowU9X4g   \n","2  2ktKjN5z8EcqmUv6EDiDgA   \n","\n","                                                                      categories  \\\n","0                                       [caribbean, food, bakeries, restaurants]   \n","1                            [restaurants, chinese, dim, sum, breakfast, brunch]   \n","2  [fashion, department, stores, automotive, shopping, wholesale, stores, tires]   \n","\n","   ... review_count  \\\n","0  ...          105   \n","1  ...          171   \n","2  ...          121   \n","\n","                                                                                                  text  \n","0  allwyns bakery love jerk chicken sandwich jerk chicken dinner roti always fresh would stay away ...  \n","1  luckee came lovely dinner husband weeks ago great dining experience enjoyed dim sum ordered obvi...  \n","2  costco got worth tires today told would long wait theyd call done waited noon till pm tires done...  \n","\n","[3 rows x 6 columns]"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"KmxmIiOMfQAP","colab_type":"code","outputId":"fee2ef22-a6f5-4cc7-c8d9-a1b7f551c829","executionInfo":{"status":"ok","timestamp":1557432950366,"user_tz":420,"elapsed":34843,"user":{"displayName":"Andrea Cruz Castillo","photoUrl":"","userId":"02285616348107227719"}},"colab":{"base_uri":"https://localhost:8080/","height":574}},"source":["# duplicate each record and assign single category to each copy of a specific record\n","dup_data = duplicate_data(data_df)\n","dup_data.head(11)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The number of single categories is  30189\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>categories</th>\n","      <th>count_features</th>\n","      <th>name</th>\n","      <th>review_count</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>YIez_A3WOt9J2SXN7OMa2Q</td>\n","      <td>[caribbean, food, bakeries, restaurants]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>allwyns bakery</td>\n","      <td>105</td>\n","      <td>allwyns bakery love jerk chicken sandwich jerk...</td>\n","      <td>caribbean</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>YIez_A3WOt9J2SXN7OMa2Q</td>\n","      <td>[caribbean, food, bakeries, restaurants]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>allwyns bakery</td>\n","      <td>105</td>\n","      <td>allwyns bakery love jerk chicken sandwich jerk...</td>\n","      <td>food</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>YIez_A3WOt9J2SXN7OMa2Q</td>\n","      <td>[caribbean, food, bakeries, restaurants]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>allwyns bakery</td>\n","      <td>105</td>\n","      <td>allwyns bakery love jerk chicken sandwich jerk...</td>\n","      <td>bakeries</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>YIez_A3WOt9J2SXN7OMa2Q</td>\n","      <td>[caribbean, food, bakeries, restaurants]</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>allwyns bakery</td>\n","      <td>105</td>\n","      <td>allwyns bakery love jerk chicken sandwich jerk...</td>\n","      <td>restaurants</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>YkAIlxYZ1guSqbbowU9X4g</td>\n","      <td>[restaurants, chinese, dim, sum, breakfast, br...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>luckee</td>\n","      <td>171</td>\n","      <td>luckee came lovely dinner husband weeks ago gr...</td>\n","      <td>restaurants</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>YkAIlxYZ1guSqbbowU9X4g</td>\n","      <td>[restaurants, chinese, dim, sum, breakfast, br...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>luckee</td>\n","      <td>171</td>\n","      <td>luckee came lovely dinner husband weeks ago gr...</td>\n","      <td>chinese</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>YkAIlxYZ1guSqbbowU9X4g</td>\n","      <td>[restaurants, chinese, dim, sum, breakfast, br...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>luckee</td>\n","      <td>171</td>\n","      <td>luckee came lovely dinner husband weeks ago gr...</td>\n","      <td>dim</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>YkAIlxYZ1guSqbbowU9X4g</td>\n","      <td>[restaurants, chinese, dim, sum, breakfast, br...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>luckee</td>\n","      <td>171</td>\n","      <td>luckee came lovely dinner husband weeks ago gr...</td>\n","      <td>sum</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>YkAIlxYZ1guSqbbowU9X4g</td>\n","      <td>[restaurants, chinese, dim, sum, breakfast, br...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>luckee</td>\n","      <td>171</td>\n","      <td>luckee came lovely dinner husband weeks ago gr...</td>\n","      <td>breakfast</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>YkAIlxYZ1guSqbbowU9X4g</td>\n","      <td>[restaurants, chinese, dim, sum, breakfast, br...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>luckee</td>\n","      <td>171</td>\n","      <td>luckee came lovely dinner husband weeks ago gr...</td>\n","      <td>brunch</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2ktKjN5z8EcqmUv6EDiDgA</td>\n","      <td>[fashion, department, stores, automotive, shop...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>costco</td>\n","      <td>121</td>\n","      <td>costco got worth tires today told would long w...</td>\n","      <td>fashion</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               business_id                                         categories  \\\n","0   YIez_A3WOt9J2SXN7OMa2Q           [caribbean, food, bakeries, restaurants]   \n","1   YIez_A3WOt9J2SXN7OMa2Q           [caribbean, food, bakeries, restaurants]   \n","2   YIez_A3WOt9J2SXN7OMa2Q           [caribbean, food, bakeries, restaurants]   \n","3   YIez_A3WOt9J2SXN7OMa2Q           [caribbean, food, bakeries, restaurants]   \n","4   YkAIlxYZ1guSqbbowU9X4g  [restaurants, chinese, dim, sum, breakfast, br...   \n","5   YkAIlxYZ1guSqbbowU9X4g  [restaurants, chinese, dim, sum, breakfast, br...   \n","6   YkAIlxYZ1guSqbbowU9X4g  [restaurants, chinese, dim, sum, breakfast, br...   \n","7   YkAIlxYZ1guSqbbowU9X4g  [restaurants, chinese, dim, sum, breakfast, br...   \n","8   YkAIlxYZ1guSqbbowU9X4g  [restaurants, chinese, dim, sum, breakfast, br...   \n","9   YkAIlxYZ1guSqbbowU9X4g  [restaurants, chinese, dim, sum, breakfast, br...   \n","10  2ktKjN5z8EcqmUv6EDiDgA  [fashion, department, stores, automotive, shop...   \n","\n","                                       count_features            name  \\\n","0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  allwyns bakery   \n","1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  allwyns bakery   \n","2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  allwyns bakery   \n","3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  allwyns bakery   \n","4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          luckee   \n","5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          luckee   \n","6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          luckee   \n","7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          luckee   \n","8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          luckee   \n","9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          luckee   \n","10  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          costco   \n","\n","    review_count                                               text  \\\n","0            105  allwyns bakery love jerk chicken sandwich jerk...   \n","1            105  allwyns bakery love jerk chicken sandwich jerk...   \n","2            105  allwyns bakery love jerk chicken sandwich jerk...   \n","3            105  allwyns bakery love jerk chicken sandwich jerk...   \n","4            171  luckee came lovely dinner husband weeks ago gr...   \n","5            171  luckee came lovely dinner husband weeks ago gr...   \n","6            171  luckee came lovely dinner husband weeks ago gr...   \n","7            171  luckee came lovely dinner husband weeks ago gr...   \n","8            171  luckee came lovely dinner husband weeks ago gr...   \n","9            171  luckee came lovely dinner husband weeks ago gr...   \n","10           121  costco got worth tires today told would long w...   \n","\n","          label  \n","0     caribbean  \n","1          food  \n","2      bakeries  \n","3   restaurants  \n","4   restaurants  \n","5       chinese  \n","6           dim  \n","7           sum  \n","8     breakfast  \n","9        brunch  \n","10      fashion  "]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"rOJefDJvZUsC","colab_type":"text"},"source":["## Split Data"]},{"cell_type":"code","metadata":{"id":"61icSBNuasKo","colab_type":"code","outputId":"7d404486-23c3-4718-850b-737d74373fc3","executionInfo":{"status":"ok","timestamp":1557432950368,"user_tz":420,"elapsed":34828,"user":{"displayName":"Andrea Cruz Castillo","photoUrl":"","userId":"02285616348107227719"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# Split dataset into 8:2 ratio\n","training_data = dup_data.sample(frac = 0.8, random_state = np.random.RandomState(seed = None)) #random.randint(0, dup_data.shape[0]))\n","\n","print('Training data has ' + str(training_data.shape[0]) + ' records.')\n","\n","testing_data = dup_data[~dup_data.isin(training_data)].dropna()\n","\n","print('Testing data has ' + str(testing_data.shape[0]) + ' records.')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training data has 24151 records.\n","Testing data has 6038 records.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6EquyNgPLK7m","colab_type":"text"},"source":["## Train Model"]},{"cell_type":"code","metadata":{"id":"JDEtb5fbi_XG","colab_type":"code","colab":{}},"source":["# Initialize model\n","model = MultinomialNB()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SA6yXUIgjqig","colab_type":"code","outputId":"72e1db64-b0d3-4947-9c9a-544ccfefdb7b","executionInfo":{"status":"ok","timestamp":1557433018533,"user_tz":420,"elapsed":102967,"user":{"displayName":"Andrea Cruz Castillo","photoUrl":"","userId":"02285616348107227719"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Train model with training data\n","model.fit(training_data.count_features.tolist(), training_data.label)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"_f0N-iDlmjQC","colab_type":"code","outputId":"1b43153e-e389-4b3e-dff1-d72ca1d34a9d","executionInfo":{"status":"ok","timestamp":1557433313417,"user_tz":420,"elapsed":18477,"user":{"displayName":"Andrea Cruz Castillo","photoUrl":"","userId":"02285616348107227719"}},"colab":{"base_uri":"https://localhost:8080/","height":363}},"source":["testing_data = testing_data.reset_index(drop = True)\n","\n","# Get probabilities of all classes for each review\n","#clean_cnt_prob = clean_count_model.predict_proba(testing_data.clean_count_features.tolist())\n","cnt_prob = model.predict_proba(testing_data.count_features.tolist())\n","# Get topNclasses for each review\n","#testing_data['count_topNclasses'] = getNclasses(clean_count_model, clean_cnt_prob, 10) \n","testing_data['count_topNclasses'] = getNclasses(model, cnt_prob, 30)\n","\n","testing_data.head(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>business_id</th>\n","      <th>categories</th>\n","      <th>count_features</th>\n","      <th>name</th>\n","      <th>review_count</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>count_topNclasses</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>YkAIlxYZ1guSqbbowU9X4g</td>\n","      <td>[restaurants, chinese, dim, sum, breakfast, br...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>luckee</td>\n","      <td>171.0</td>\n","      <td>luckee came lovely dinner husband weeks ago gr...</td>\n","      <td>sum</td>\n","      <td>[restaurants, bars, food, new, american, night...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>YkAIlxYZ1guSqbbowU9X4g</td>\n","      <td>[restaurants, chinese, dim, sum, breakfast, br...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>luckee</td>\n","      <td>171.0</td>\n","      <td>luckee came lovely dinner husband weeks ago gr...</td>\n","      <td>breakfast</td>\n","      <td>[restaurants, bars, food, new, american, night...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2ktKjN5z8EcqmUv6EDiDgA</td>\n","      <td>[fashion, department, stores, automotive, shop...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>costco</td>\n","      <td>121.0</td>\n","      <td>costco got worth tires today told would long w...</td>\n","      <td>department</td>\n","      <td>[automotive, services, shopping, repair, auto,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2ktKjN5z8EcqmUv6EDiDgA</td>\n","      <td>[fashion, department, stores, automotive, shop...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>costco</td>\n","      <td>121.0</td>\n","      <td>costco got worth tires today told would long w...</td>\n","      <td>wholesale</td>\n","      <td>[automotive, services, shopping, repair, auto,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2ktKjN5z8EcqmUv6EDiDgA</td>\n","      <td>[fashion, department, stores, automotive, shop...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>costco</td>\n","      <td>121.0</td>\n","      <td>costco got worth tires today told would long w...</td>\n","      <td>stores</td>\n","      <td>[automotive, services, shopping, repair, auto,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              business_id                                         categories  \\\n","0  YkAIlxYZ1guSqbbowU9X4g  [restaurants, chinese, dim, sum, breakfast, br...   \n","1  YkAIlxYZ1guSqbbowU9X4g  [restaurants, chinese, dim, sum, breakfast, br...   \n","2  2ktKjN5z8EcqmUv6EDiDgA  [fashion, department, stores, automotive, shop...   \n","3  2ktKjN5z8EcqmUv6EDiDgA  [fashion, department, stores, automotive, shop...   \n","4  2ktKjN5z8EcqmUv6EDiDgA  [fashion, department, stores, automotive, shop...   \n","\n","                                      count_features    name  review_count  \\\n","0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  luckee         171.0   \n","1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  luckee         171.0   \n","2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  costco         121.0   \n","3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  costco         121.0   \n","4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  costco         121.0   \n","\n","                                                text       label  \\\n","0  luckee came lovely dinner husband weeks ago gr...         sum   \n","1  luckee came lovely dinner husband weeks ago gr...   breakfast   \n","2  costco got worth tires today told would long w...  department   \n","3  costco got worth tires today told would long w...   wholesale   \n","4  costco got worth tires today told would long w...      stores   \n","\n","                                   count_topNclasses  \n","0  [restaurants, bars, food, new, american, night...  \n","1  [restaurants, bars, food, new, american, night...  \n","2  [automotive, services, shopping, repair, auto,...  \n","3  [automotive, services, shopping, repair, auto,...  \n","4  [automotive, services, shopping, repair, auto,...  "]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"sxEpdjaSjOgH","colab_type":"code","colab":{}},"source":["\"\"\"with open(sets_dir) as sets_file:\n","  sets_list = []\n","  for item in sets_file:\n","    #print(set([item]))\n","    sets_list.append(set(item))\n","    \n","print(sets_list[0:5])\n","\n","\"\"\"\n","with open(main_dir + 'sets.json', 'r') as f:\n","  sets_list = []\n","  r = json.load(f)\n","  for item in r:\n","    sets_list.append(set(item))\n","#sets_list = load_data(sets_dir)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHJBsndInEMp","colab_type":"code","colab":{}},"source":["pred_sets = compare_to_set(testing_data.count_topNclasses, sets_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EIEzwxvknIj5","colab_type":"code","colab":{}},"source":["# compare the list of predicted labels to the actual labels\n","cnt_tp, cnt_fp, cnt_length = compareLists(testing_data.count_topNclasses, testing_data.categories)\n","set_tp, set_fp, set_length = compareLists(pd.Series(pred_sets), testing_data.categories)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eQF_nzwknNG5","colab_type":"code","outputId":"5702f82e-6cc5-4dd7-8b97-07a7955417e4","executionInfo":{"status":"ok","timestamp":1557433317487,"user_tz":420,"elapsed":14187,"user":{"displayName":"Andrea Cruz Castillo","photoUrl":"","userId":"02285616348107227719"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["# Display precison and recall\n","cnt_recall = (np.mean(np.divide(cnt_tp,cnt_length)) * 100)\n","cnt_precision = (np.mean(np.divide(cnt_tp, np.add(cnt_tp, cnt_fp)))) * 100\n","print(\"Count w/ Name Recall: %2.4f       |  Count w/ Name Precision: %2.4f\" %(cnt_recall,cnt_precision))\n","\n","print(\"===========================================================================\")\n","\n","set_recall = (np.mean(np.divide(set_tp,set_length)) * 100)\n","set_precision = (np.mean(np.divide(set_tp, np.add(set_tp, set_fp)))) * 100\n","print(\"Count Set w/ Name Recall: %2.4f   |  Count Set w/ Name Precision: %2.4f\" %(set_recall,set_precision))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Count w/ Name Recall: 72.5957       |  Count w/ Name Precision: 19.4474\n","===========================================================================\n","Count Set w/ Name Recall: 70.7769   |  Count Set w/ Name Precision: 19.0651\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8ofThqC7vxCe","colab_type":"code","outputId":"02f246f1-5558-4cb0-e5fd-ea598e38f35a","executionInfo":{"status":"ok","timestamp":1558028703266,"user_tz":420,"elapsed":6455,"user":{"displayName":"Andrea Cruz Castillo","photoUrl":"","userId":"02285616348107227719"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]}]}